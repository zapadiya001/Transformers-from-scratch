{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3PqsZXoM4loT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single head attention"
      ],
      "metadata": {
        "id": "R9eWBXADABXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 4, 6)   # (batch=1, seq_len=4, dim=6)\n",
        "\n",
        "W_q = torch.randn(6, 6)\n",
        "W_k = torch.randn(6, 6)\n",
        "W_v = torch.randn(6, 6)\n",
        "\n",
        "Q = x @ W_q     # (1,4,6)\n",
        "K = x @ W_k     # (1,4,6)\n",
        "V = x @ W_v     # (1,4,6)\n",
        "\n",
        "scores = Q @ K.transpose(-2, -1) / math.sqrt(6)   # (1,4,4)\n",
        "scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stZMiz6P_6qS",
        "outputId": "0e89cdff-55e3-4841-d419-7271019fe4f3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding Mask\n",
        "- let we assume a padded sequence\n",
        "tokens = [x1, x2, x3, pad]"
      ],
      "metadata": {
        "id": "y3sZhQ12_r3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a mask\n",
        "# help to zero out the non existant part\n",
        "pad_mask = torch.tensor([[1,1,1,0]]) # (1,4)\n",
        "\n",
        "pad_mask_expanded = pad_mask.unsqueeze(1) # convert (1,4) into (1,1,4) for the computation with scores tensor\n",
        "pad_mask_expanded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk-VZXQo_rlt",
        "outputId": "fc869f9f-e0e3-4e96-f94b-2a933e8bcbe4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting 1 -> 0 (allowed) and 0 -> -inf (block)\n",
        "\n",
        "scores_masked = scores.masked_fill(pad_mask_expanded == 0, float('-inf'))\n",
        "# masked_fill(mask,value) # if mask true -> keep original else assign value to it"
      ],
      "metadata": {
        "id": "wai1Uzi0Awtw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn = F.softmax(scores_masked, dim=-1)\n",
        "attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6j8mOUnJ7NW",
        "outputId": "3ab8ac00-f5f8-4e30-8fa6-db954efa9083"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.9768e-01, 6.3114e-01, 1.7118e-01, 0.0000e+00],\n",
              "         [6.2592e-01, 1.4123e-03, 3.7266e-01, 0.0000e+00],\n",
              "         [2.2770e-02, 9.5557e-01, 2.1659e-02, 0.0000e+00],\n",
              "         [2.6485e-04, 9.9972e-01, 1.0329e-05, 0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- last past is zero, so it would not considered in the computation"
      ],
      "metadata": {
        "id": "wNsKUa92J-ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = attn @ V # (1,4,4) X (1,4,6) -> (1,4,6)"
      ],
      "metadata": {
        "id": "w6HArXpFJMm-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('input: \\n',x)\n",
        "print('output: \\n',output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSoMcFKzJZWw",
        "outputId": "94861644-9f98-4b68-eba7-6841a4c072f2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: \n",
            " tensor([[[-1.0791, -0.3096,  1.1264,  0.9998,  1.1162,  0.8280],\n",
            "         [-0.3296, -1.8103, -0.5017,  1.2415, -1.2396, -0.3374],\n",
            "         [-1.3646, -0.3819,  0.8389,  0.8109,  1.9820,  0.4137],\n",
            "         [-0.3675, -1.4777,  1.9310, -0.9693, -1.3933,  0.3477]]])\n",
            "output: \n",
            " tensor([[[ 2.5162, -0.3909, -3.9355,  3.2794,  0.6374,  3.9869],\n",
            "         [ 3.2079,  3.7480, -0.3780,  2.7375,  0.1082,  0.2387],\n",
            "         [ 2.1723, -2.5449, -5.7781,  3.5293,  0.8449,  5.9320],\n",
            "         [ 2.1258, -2.8386, -6.0291,  3.5624,  0.8713,  6.1971]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- padding mask : zero out the part which do not exist"
      ],
      "metadata": {
        "id": "3jFL6MncJ3lD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Casual mask - no looking ahead\n",
        "- during training transformer act as non-autoregressively and during inference act as autoregressively\n",
        "- so we need to stop transformer to from seeing(train) on future sequence(data)\n",
        "\n",
        "- casual mask mimick the behaviour of autoregressive during non-autoregressive training"
      ],
      "metadata": {
        "id": "ivK3P64HKb-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = x.size(1)\n",
        "seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s769LuS4JtWJ",
        "outputId": "1aba956c-9c8e-4484-be1a-490a7996a707"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "casual_mask = torch.triu(torch.ones(seq_len,seq_len), diagonal=1)\n",
        "# torch.triu(matrix,dim=1) -> convert matrix into upper trinagle\n",
        "# for dim = 1 upper trinangle , for dim = 0 lower triangle\n",
        "\n",
        "casual_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMl9bZH1KW18",
        "outputId": "0f0c3e92-b994-458b-ea99-fa186a2b4852"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_masked = scores.masked_fill(casual_mask.bool(), float('-inf'))\n",
        "\n",
        "scores_masked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyxpQw6lLit5",
        "outputId": "149363ea-c11e-4e7c-a717-1e8354d43823"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -2.6225,     -inf,     -inf,     -inf],\n",
              "         [ -0.2130,  -6.3070,     -inf,     -inf],\n",
              "         [ -2.9483,   0.7886,  -2.9983,     -inf],\n",
              "         [  0.6890,   8.9251,  -2.5553, -14.8012]]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- now 1st token only sees first 1st one, 2nd only upto 2nd and so on\n",
        "- i the token would not going to see ith+ token"
      ],
      "metadata": {
        "id": "VKb3cozON_sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn = F.softmax(scores_masked, dim=-1)\n",
        "\n",
        "attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-f5k1VcLuR2",
        "outputId": "82ed3011-68f4-41f4-b6a7-111566fd7635"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [9.9775e-01, 2.2513e-03, 0.0000e+00, 0.0000e+00],\n",
              "         [2.2770e-02, 9.5557e-01, 2.1659e-02, 0.0000e+00],\n",
              "         [2.6485e-04, 9.9972e-01, 1.0329e-05, 4.9624e-11]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = attn @ V"
      ],
      "metadata": {
        "id": "YLwgEM1wL7gV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('input: \\n',x)\n",
        "print('output: \\n',output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PyddGCKL9uU",
        "outputId": "4cef3e44-bee7-4509-eb23-cc757e331180"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: \n",
            " tensor([[[-1.0791, -0.3096,  1.1264,  0.9998,  1.1162,  0.8280],\n",
            "         [-0.3296, -1.8103, -0.5017,  1.2415, -1.2396, -0.3374],\n",
            "         [-1.3646, -0.3819,  0.8389,  0.8109,  1.9820,  0.4137],\n",
            "         [-0.3675, -1.4777,  1.9310, -0.9693, -1.3933,  0.3477]]])\n",
            "output: \n",
            " tensor([[[ 3.3110,  3.5816, -0.4492,  2.4966, -0.4249,  0.3445],\n",
            "         [ 3.3084,  3.5671, -0.4618,  2.4990, -0.4220,  0.3577],\n",
            "         [ 2.1723, -2.5449, -5.7781,  3.5293,  0.8449,  5.9320],\n",
            "         [ 2.1258, -2.8386, -6.0291,  3.5624,  0.8713,  6.1971]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined mask - padding mask + causal mask\n",
        "\n",
        "- let assume that sequence is [x1,x2,x3,pad]\n"
      ],
      "metadata": {
        "id": "GqQoM7D9MaKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask = casual_mask.unsqueeze(0) # (4 x 4) -> (1 x 4 x 4) to compute with input shape"
      ],
      "metadata": {
        "id": "tEt9uduhMHho"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask.shape, combined_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6SOQJkQMY3F",
        "outputId": "de23936c-4e5a-4f31-b164-a2277fc8d63f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 4, 4]),\n",
              " tensor([[[0., 1., 1., 1.],\n",
              "          [0., 0., 1., 1.],\n",
              "          [0., 0., 0., 1.],\n",
              "          [0., 0., 0., 0.]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask += (pad_mask == 0).unsqueeze(1) # (1,4,4) + (1,1,4)"
      ],
      "metadata": {
        "id": "C3N1LX_lTfPL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG67ez4ZTszd",
        "outputId": "e27958cc-a451-4538-ba18-53984c739353"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 1., 1., 2.],\n",
              "         [0., 0., 1., 2.],\n",
              "         [0., 0., 0., 2.],\n",
              "         [0., 0., 0., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_masked = scores.masked_fill(combined_mask.bool(), float('-inf'))\n",
        "# 0 -> no change, 1 or 2 -> inf (would be zero during softmax)\n",
        "\n",
        "scores_masked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YwgFvKrUXkc",
        "outputId": "4e92dc97-676d-46e0-d64a-450e34f7bdfb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.6225,    -inf,    -inf,    -inf],\n",
              "         [-0.2130, -6.3070,    -inf,    -inf],\n",
              "         [-2.9483,  0.7886, -2.9983,    -inf],\n",
              "         [ 0.6890,  8.9251, -2.5553,    -inf]]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn = F.softmax(scores_masked, dim=-1)\n",
        "\n",
        "attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-BKLGfFVIsp",
        "outputId": "b864617b-5bb1-4057-e62a-7ea3da3408e8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [9.9775e-01, 2.2513e-03, 0.0000e+00, 0.0000e+00],\n",
              "         [2.2770e-02, 9.5557e-01, 2.1659e-02, 0.0000e+00],\n",
              "         [2.6485e-04, 9.9972e-01, 1.0329e-05, 0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = attn @ V\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loHLwm0fVK-b",
        "outputId": "1cdbb920-ef0f-48bf-e180-7b0d138ac651"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.3110,  3.5816, -0.4492,  2.4966, -0.4249,  0.3445],\n",
              "         [ 3.3084,  3.5671, -0.4618,  2.4990, -0.4220,  0.3577],\n",
              "         [ 2.1723, -2.5449, -5.7781,  3.5293,  0.8449,  5.9320],\n",
              "         [ 2.1258, -2.8386, -6.0291,  3.5624,  0.8713,  6.1971]]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}